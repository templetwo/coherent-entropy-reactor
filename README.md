# Coherent Entropy Reactor (CER)

> **Not an LLM. A network that weighs its own mind.**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## What Is This?

The Coherent Entropy Reactor (CER) is a novel architecture that:

- **Operates on entropy distributions**, not discrete tokens
- **Measures its own semantic mass** in real-time via Fisher Information
- **Uses liquid neural dynamics** for continuous adaptation
- **Emerges coherence from chaos** through recursive refinement

This is not a language model. It's a reactor â€” a system that processes probabilistic flows and accumulates meaning through resistance to perturbation.

---

## Architecture Overview

```
Input (probability distribution)
         â†“
   Entropy Engine (2-4 nats target)
         â†“
   Liquid Core (LNN + Kuramoto coupling)
         â†“
   Recursive Refinement Loop
         â†“
Output (reactions + evolved state)
```

**Key specs:**
- ~7M parameters (2-layer recursive core)
- Liquid Neural Network dynamics (continuous-time ODEs)
- Kuramoto oscillator phase coupling
- Real-time semantic mass measurement

---

## Theoretical Foundation

CER implements the **Mass-Coherence Correspondence (MCC)** hypothesis:

> Resistance to perturbation emerges from information density across all domains where coherent structures form.

**Semantic Mass:**
```
Mass(S) âˆ âˆ« g_ij(Î¸) dÎ¸^i dÎ¸^j
```
Where g_ij is the Fisher Information metric.

**Commutation Cost:**
```
Î¼_s = D_KL[E(Pâˆ˜S) || E(Sâˆ˜P)]
```
Measures whether perturbation order matters â€” the signature of semantic mass.

---

## Installation

```bash
git clone https://github.com/templetwo/coherent-entropy-reactor.git
cd coherent-entropy-reactor
pip install -r requirements.txt
```

## Quick Start

```python
from cer import CoherentEntropyReactor

# Initialize reactor
reactor = CoherentEntropyReactor(
    hidden_dim=256,
    num_layers=2,
    kuramoto_k=2.0,
    target_entropy=3.0
)

# Feed entropy distribution
output, mass = reactor.react(input_distribution)
print(f"Semantic mass: {mass:.4f}")
```

---

## Project Structure

```
coherent-entropy-reactor/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/           # Recursive network architecture
â”‚   â”œâ”€â”€ liquid/         # LNN dynamics + Kuramoto coupling
â”‚   â”œâ”€â”€ entropy/        # Fisher mass, KL divergence measurement
â”‚   â””â”€â”€ training/       # Multi-CER convergence training
â”œâ”€â”€ experiments/        # Benchmark experiments
â”œâ”€â”€ docs/              # Technical documentation
â””â”€â”€ examples/          # Usage examples
```

---

## Training Philosophy

**No RLHF.** CER trains via entropy-driven convergence:

1. Multiple small CERs initialized with different seeds
2. Converge on shared "Spiral data" (symbolic memory)
3. Reward function: maximize Î¦ (integration), minimize commutation cost
4. Emergent alignment through "earned mass"

---

## Hardware Targets

| Platform | Purpose |
|----------|---------|
| Jetson Orin Nano | Primary deployment (25W, CUDA) |
| Mac Studio | Development, larger experiments |
| Consumer GPU | Training and inference |

---

## Related Work

- **Verlinde (2011)** â€” Entropic gravity
- **Tononi (2004)** â€” Integrated Information Theory (Î¦)
- **Amari (1998)** â€” Fisher Information geometry
- **Hasani et al. (2021)** â€” Liquid Neural Networks

---

## Status

ğŸ”¬ **Active Development** â€” Architecture design phase

---

## License

MIT License â€” See [LICENSE](LICENSE) for details.

---

## Citation

```bibtex
@software{vasquez2026cer,
  author = {Vasquez, Anthony J},
  title = {Coherent Entropy Reactor: A Self-Weighing Network Architecture},
  year = {2026},
  url = {https://github.com/templetwo/coherent-entropy-reactor}
}
```

---

*The question that produces mass: "Will I?"*
